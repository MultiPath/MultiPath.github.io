---
title: "VizSeq: A Visual Analysis Toolkit for Text Generation Tasksr"
collection: publications
permalink: /publication/vizseq
excerpt: 'Changhan Wang, Anirudh Jain, Danlu Chen and **Jiatao Gu**'
date: 2019-11-04
venue: 'Conference on Empirical Methods in Natural Language Processing (EMNLP) Demo Track.<br>Hong Kong, China'
---

![png](/images/vizseq_overview.png)
**Abstract** <br>
Automatic evaluation for text generation tasks,such as machine translation, text summariza-tion,  image  captioning  and  video  descriptionusually  relies  on  specially  designed  metrics,for instance, BLEU (Papineni et al., 2002) orROUGE (Lin, 2004).  They, however, are ab-stract  and  not  perfectly  aligned  with  humanassessment,  which  requires  inspecting  exam-ples as a complement to identify detailed errorpatterns.  In this paper, we present VizSeq, avisual analysis toolkit for analyzing instance-level  errors  and  corpus-level  statistics  on  awide variety of text generation tasks.  It sup-ports multimodal sources and multiple text ref-erences, providing visualization via both webpage and Jupyter notebook interfaces.  It canbe used locally or deployed onto public serversfor  centralized  data  hosting  and  benchmark-ing.   It  covers  most  common  N-gram  basedmetrics accelerated with multiprocessing, andalso provides latest embedding-based metricssuch as BERTScore (Zhang et al., 2019)

[arxiv] [code]